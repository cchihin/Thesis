\chapter{Numerical Techniques}\label{chap:3}
In this chapter, I will present the numerical methods relevant to this thesis.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 3.1 METHOD OF WEIGHTED RESIDUALS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Method of weighted residuals}
The incompressible Navier-Stokes equations describe the time- and spatial-varying velocity field and pressure field. To represent the spatially-dependent velocity and pressure fields, spatial discretisation is performed using the spectral/\emph{hp} element method. Other popular methods of spatial discretisation found in literature are the finite-difference methods, and finite-volume methods.
SEMs belong to a general class of methods known as the method of weighted residual, a generic method for approximating a solution of a differential equation. The method of weighted residual will be described with a worked example as follows. Consider that the solution of a differential equation $u(x)$ can be represented as an infinite sum of \emph{trial} functions (also known as basis functions, expansion functions, mode shapes).
\begin{equation}\label{eq:infiniteExpansions}
    u(x) = \sum_{i=0}^{\infty} \hat{u}_i \phi_i(x),
\end{equation}
where $\phi_i(x)$ are the \emph{trial} functions and $\hat{u}_i$ are the trial function coefficients to be determined. Typical examples of trial functions are, Fourier series $e^{ikx}$, Chebyshev polynomials $T(x)$ or Legendre series $L_g(x)$. The choice of basis expansions depends on the given problem. In the context fluid mechanics, the Fourier series can be used to represent isotropic turbulence with homogenenous (periodic) boundary conditions. In a channel flow, Fourier series are used in the homogenenous streamwise ad spanwise directions while Chebyshev or Legendre polynomials are used in the wall-normal direction. Consider equation \ref{eq:infiniteExpansions} to be a solution of a 1-dimensional Poisson equation, bounded by the domain $\Omega \in [x_a, x_b]$,
\begin{equation}\label{eq:linearOperator}
    \mathbb{L}u(x) \equiv \frac{\partial u(x)}{\partial x} - \lambda u(x) = f(x), \qquad x_a \leq x \leq x_b,
\end{equation}
with the appropriate boundary conditions, and $\mathbb{L}$ refers to a linear differential operator. Note that equation \ref{eq:infiniteExpansions} exactly satisfies the differential equation of \ref{eq:linearOperator} i.e $\mathbb{L}u(x)- f(x) = 0$. The exact solution would require a computation of infinite basis coefficients $\hat{u}$ which is practically infeasible. Therefore, an approximate solution $u^\delta(x)$ is sought after by truncating an infinite number of basis expansions to a finite number,
\begin{equation}\label{eq:truncatedExpansions}
    u(x) \approx u^\delta (x) = \sum_{i=0}^{K}\hat{u_i}\phi_i(x),
\end{equation}
where there is a finite number of $K$ basis expansions. The approximate solution does not satisfy \ref{eq:linearOperator} exactly, leading to an 'error' known as a residual,
\begin{equation}
    R(u^\delta(x)) = \mathbb{L}u^\delta(x) - f(x)
\end{equation}
where $R(u^\delta)$ is the residual. The residual depends on the approximate solution $u^\delta(x)$, which varies in $x$. In other words, the error is non-zero and varies within $\Omega$. Although equation \ref{eq:linearOperator} may not be satisfied everywhere in $\Omega$, it is possible to apply some restrictions (conditions) on the residual so that it tends to zero by the choice of restrictions imposed. An approximate solution has $K+1$ unknowns ($\hat{u}_0, ...,\hat{u}_K$), hence, it is natural to impose $K+1$ restrictions on the residual to form a determined system and the type of restriction defines the numerical method. 

The method of weighted residual is a general method that allows for various types the restriction to be implemented. The method "nullifies" the residual by equating the inner product with a \emph{test} function, $v_j(x)$ (also known as a weight function - hence the name 'weighted residual') to zero,
\begin{equation}\label{eq:residual}
    (v_j(x), R(u^\delta(x))) = \int_{x_a}^{x_b} v_j\,R(u^\delta(x))\; \mathrm{d}x = 0, \qquad j = 0,...,K.
\end{equation}
The type of restriction on the residual is implemented through the choice of \emph{test} function, $v_j$. For instance, for $v_j = \delta(x-x_j)$, the numerical method becomes the \emph{collocation} method where the differential equation is satisfied on discrete points $x_j$. Table \ref{tab:weightFunction} shows the different forms of weight functions and its corresponding numerical method. The choice of \emph{test} function is also commonly known as projection methods, i.e projecting (taking the inner product) the residual onto the \emph{test} functions. It is worth to mention that the method of weighted residual merely describe the projection method but does not specify the type of \emph{trial} functions used. The choice of \emph{trial} functions used in \emph{nektar++} will be elaborated in Section \ref{sec:modifiedBasis}.
\renewcommand{\arraystretch}{2.5} % Default value: 1
\begin{table}[h]
    \centering
        \begin{tabular}{cc}
            \hline
            Weight Function& Type of method \\
            \hline
            $v_j(x) = \delta(x-x_j)$ & Collocation \\
            $v_j(x) =\left\{\begin{array}{ll}
                1 & \mbox{if } x \in \Omega_j\\
                0 & \mbox{if } x \notin \Omega_j \\
           \end{array}\right. $& Finite-Volume \\
            $v_j(x) = \phi_j$& Galerkin \\
            $v_j(x) = \frac{\partial R}{\partial \hat{u}_j}$ & Least-squares \\
            \hline
        \end{tabular}
        \caption{Types of weight function}
    \label{tab:weightFunction}
\end{table}

% \subsection{Galerkin methods}
Galerkin methods are commonly found in finite/spectral element solvers, used in \emph{nektar++}. The Galerkin method belongs to a general class of weighted residual methods that assumes the \emph{trial} functions take on the same form as the \emph{test} functions (Table \ref{tab:weightFunction}). To describe the method, a worked example is illustrated. The Galerkin method is appplied to solve the Poisson equation \ref{eq:linearOperator} with the following boundary conditions,
\begin{equation}\label{eq:boundaryConditions}
    B^- = g^- \quad \textrm{at} \quad x = x_a, \qquad B^+ = g^+ \quad \textrm{at} \quad x = x_b
\end{equation}
where $B^-$, $B^+$ are the boundary conditions which could be either Dirichlet, Neumann or Robin conditions. Equation \ref{eq:linearOperator} and \ref{eq:boundaryConditions} together forms a boundary value problem and is said to be in the \emph{strong} \footnote{\emph{strong} loosely mean that the trial functions are required to be both $C^0$ and $C^1$ continuous} form. The Galerkin method assumes that the trial functions $\phi_i(x)$ satisfies equation \ref{eq:linearOperator} with homogeneous boundary conditions,
\begin{equation}
    \phi_i(x_a) = \phi_i(x_b) = 0.
\end{equation}
Next, the solution $u(x)$ is decomposed into a linear combination of $\tilde{u}(x)$ and $u^H(x)$,
\begin{equation}
    u(x) = \tilde{u}(x) + u^H(x),
\end{equation}
where $\tilde{u}(x)$ is any function that satisfy the boundary conditions assosciated with equation \ref{eq:boundaryConditions} and $u^H(x)$ is the homogeneous solution that satisfies the homogeneous boundary conditions - $B_H^-(x_a) = B_H^+(x_b) = 0$. The resulting problem for $u^H(x)$ becomes
\begin{equation}\label{eq:linearHomogeneous}
    \mathbb{L}u^H(x) - h(x) = 0, \qquad x_a \leq x \leq x_b,
\end{equation}
where $h =  f(x) - \mathbb{L}\tilde{u}(x)$. It is worth noting that the steps thus simply mathematical, and no approximation have been made. The solutions of $u(x) = \tilde{u}(x) - u^H(x)$ represented by an infinite expansions (equation \ref{eq:infiniteExpansions}) are exact. Next, the homogeneous solution  $u^H(x)$ can be approximated by a finite expansion of \emph{trial} functions,
\begin{equation}\label{eq:homogeneousCoefficients}
    u^H(x) \approx u^{H,\delta} (x) = \sum_{i=0} ^ K \hat{u}^{H,\delta}_i\phi_i(x),
\end{equation}
where $\hat{u}^{H,\delta}_i$ are the coefficients to be determined. Since $\phi_i(x)$ satisfies the homogeneous boundary conditions, $\hat{u}^{H, \delta}_i$ can take on any values and $u^{H, \delta}(x)$ will still satisfy the homogeneous boundary conditions. Substituing the approximate solution of $u^{H,\delta}(x)$ into equation \ref{eq:linearHomogeneous}, and applying the method of weighted resiudal,
\begin{equation}\label{eq:galerkinResidual}
    (R(u^{H,\delta}), v_j(x)) = \int_{x_a}^{x_b} \left(\mathbb{L}u^{H,\delta}(x) - h(x) \right) v_j(x) \; \mathrm{d}x = 0, \qquad j=0, ..., K,
\end{equation}
where $v_j(x)$ is some \emph{test} function and there are $K+1$ finite expansions. In the Galerkin method (or Bubnov-Galerkin), the weight function $v_j(x)$ takes on the same form as the trial functions $\phi_j(x)$ (Table \ref{tab:weightFunction}). In other words, the differential equation is satisfied when projected on the \emph{test/trial} functions. Substituting equation \ref{eq:homogeneousCoefficients} into the residual equation \ref{eq:galerkinResidual} and applying $v_j(x) = \phi_j(x)$,
\begin{equation}\label{eq:generalisedGalerkin}
    \sum_{i=0}^{K} \hat{u}^{H,\delta}_i \int_{x_a}^{x_b} \mathbb{L}\phi_i\phi_j \; \mathrm{d}x = \int_{x_a}^{x_b} \left(f(x) - \mathbb{L}\tilde{u}(x) \right) \phi_j \; \mathrm{d}x, \qquad j = 0, .., K
\end{equation}
Equation \ref{eq:generalisedGalerkin} furnishes a system of $K+1$ linear equations with $K+1$ unknowns i.e $\{\hat{u}^{H,\delta}_0,....,\hat{u}^{H,\delta}_K\}$. Applying integration by parts to equation \ref{eq:generalisedGalerkin}, the equation reduces to,
\begin{equation}
    \sum_{i=0}^K \hat{u}_i^{H,\delta} \left[\int_{x_a}^{x_b} \frac{\partial \phi_j}{\partial x}\frac{\partial \phi_i}{\partial x} + \lambda \phi_j\phi_i \; \mathrm{d}x\right] = - \int_{x_a}^{x_b} \frac{\partial \tilde{u}}{\partial x}\frac{\partial \phi_j}{\partial x} + (\lambda\tilde{u} + f(x))\phi_j \; \mathrm{d}x,
\end{equation}
which is known as the \emph{weak}\footnote{\emph{trial} functions are only required to be $C^0$ continuous} form. The boundary conditions of the \emph{weak} form naturally appears in the right-hand side of equation \ref{eq:systemOfLinear}, which makes it convenient to implement. Equation \ref{eq:generalisedGalerkin} can be re-written in matrix form,
\renewcommand{\arraystretch}{1.25} % Default value: 1
\begin{equation}\label{eq:systemOfLinear}
    \begin{split}
    &\begin{bmatrix}
        \int_{x_a}^{x_b} \frac{\partial \phi_0}{\partial x}\frac{\partial \phi_0}{\partial x} + \lambda\phi_0\phi_0 \; \mathrm{d}x & \hdots & 
        \int_{x_a}^{x_b} \frac{\partial \phi_0}{\partial x} \frac{\partial \phi_K}{\partial x} + \lambda\phi_0\phi_K \; \mathrm{d}x \\
        \vdots & \ddots & \vdots \\
        \int_{x_a}^{x_b} \frac{\partial \phi_K}{\partial x}\frac{\partial \phi_0}{\partial x} + \lambda\phi_0\phi_0 \; \mathrm{d}x & \hdots & 
        \int_{x_a}^{x_b} \frac{\partial \phi_K}{\partial x} \frac{\partial \phi_K}{\partial x} + \lambda\phi_0\phi_K \; \mathrm{d}x \\
    \end{bmatrix}
    \begin{bmatrix}
        \hat{u}_0^{H,\delta} \\ \vdots \\ \hat{u}_K^{H, \delta}
    \end{bmatrix}
    = \\
    &\begin{bmatrix}
        -\int_{x_a}^{x_b} \frac{\partial \tilde{u}}{\partial x} \frac{\partial \phi_0}{\partial x} + (\lambda \tilde{u} + f(x))\phi_0 \; \mathrm{d}x \\ 
        \vdots \\ 
        -\int_{x_a}^{x_b} \frac{\partial \tilde{u}}{\partial x} \frac{\partial \phi_K}{\partial x} + (\lambda \tilde{u} + f(x))\phi_K \; \mathrm{d}x \\ 
    \end{bmatrix}
    \end{split}
\end{equation}
where $\mathbf{\hat{u}}^{H,\delta} = [\hat{u}_0^{H,\delta}, ..., \hat{u}_K^{H, \delta}]$ is determined by solving the system of linear equations. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 3.2 Spectral/hp element methods
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Spectral/{hp} element methods}
The spectral/{hp} element method (SEM) is related to the Galerkin method in which the type of \emph{trial} function used. The spectral/\emph{hp} element method combines 2 traditional numerical methods, namely, 
\begin{enumerate}
    \item Finite elements:
        \subitem The finite element method decomposes the global domain into a set of non-overlapping subdomains (finite elements), represented by linear shape functions. In a 1D domain, the size of each element is given by $h$ and the approximate solution should covergence as $h$ is decreased - also known as \emph{h}-refinement. The flexibility of domain decomposition allows for complex engineering geometries to be represented. 
    \item Spectral method:
        \subitem The spectral method performs a global discretisation of the domain. The domain is represented by a linear combination of global continuous functions, such as the Fourier series. Spectral methods benefit from the property of \emph{spectral convergence}, where the solution error decreases by $\mathcal{O}(c^{-N})$, where $c$ is some constant $0 \leq c \leq 1$ and $N$ is the number of polynomials (\cite{trefethen_2000}). In other words, as the number of functions is increased, the error decreases exponentially.
\end{enumerate}
The Spectral/\emph{hp} element method leverages the advantages of both methods - geometric flexibility and spectral covergence. The spectral/\emph{hp} method uses a series of high-order polynomials (Lagrange/Legendre) within each element. Considering each element consists of $P+1$ linearly independent polynomials (where $P$ refers to the highest polynomial order) spanning the polynomial space of $\mathcal{P}_P$, the error of a smooth solution with mesh-size $h$ and polynomial order $P$ has the property of (\cite{karniadakis_2005spectral}),
\begin{equation}\label{eq:errorConvergence}
    ||u(x) - u^{\delta}(x)|| \leq Ch^P||u(x)|| \approx \mathcal{O}(h^P).
\end{equation}
Equation \ref{eq:errorConvergence} implies that the error decreases as the $h$ is decrease (mesh refinement) or as $P$ is increased using higher-order polynomials.

% \subsection{Polynomial expansions in SEM}\label{sec:modifiedBasis}
The \emph{trial} functions $\phi_p$ (or basis expansions) used in spectral/\emph{hp} method consist of \emph{boundary} and \emph{interior} modes. \emph{Interior} modes are defined to be zero on all boundaries, and non-zero within the boundary, satisfying homogeneous boundary conditions. \emph{Boundary} modes take on non-zero values on the boundary, satisfying non-homogeneous boundary conditions and providing $C^0$ continuity between elements (\cite{karniadakis_2005spectral}).
Within the \emph{nektar++} framework, the Jacobi polynomials $\mathbb{P}_p^{\alpha.\beta}(\xi)$ modified with linear elements are used as the \emph{trial} functions. Using $\alpha=1$, $\beta=1$, and linear basis functions as \emph{boundary} modes, the modified Jacobi polynomials are,
\renewcommand{\arraystretch}{1.25} % Default value: 1
\begin{equation}\label{eq:modifiedJacobi}
    \phi_p(\xi) = \psi_p(\xi) = \left\{
            \begin{array}{ll}
                \frac{1-\xi}{2} & \mbox{for } p=P\\
                \frac{1-\xi}{2}\frac{1+\xi}{2}\mathbb{P}_{P-1}(\xi)^{1,1} & \mbox{for } P \geq 2 \\
                \frac{1+\xi}{2} & \mbox{for } p=P,
           \end{array}\right.
\end{equation}
where $P$ denotes the highest polynomial order. Figure \ref{fig:Modified Jacobi polynomials} shows the modified Jacobi polynomials for $p \in [0, 5]$ described by equation \ref{eq:modifiedJacobi}. The boundary modes are $\psi_0$ and $\psi_5$ while the rest are boundary modes.
\begin{figure}[h]
    \centering
        \includegraphics[width=15cm]{NumericalTechniques/Figures/modifiedBasis.pdf}
        \caption{Modified Jacobi polymoials $\psi_p$ for $p \in [0, 5]$}
        \label{fig:Modified Jacobi polynomials}
\end{figure}

% \subsection{Fourier spectral/\emph{hp} modes}
The Fourier spectral/\emph{hp} element method uses a combination of Fourier expansions and spectral/\emph{hp} element method to discretise the spatial domain. In a turbulent channel flow, the Fourier expansions are used to represent the periodic streamwise and cross stream directions, while the spectral/\emph{hp} elements are used to discretise the wall-normal direction. Within the \emph{nektar++} framekwork, the Fourier spectral/\emph{hp} element method (also known as a Quasi-3D approach), can be implemented either with 2D spectral/\emph{hp} elements and 1D Fourier expansions (3DH1D) or 1D spectral/\emph{hp} elements and 2D Fourier expansions (3DH2D). In this work, the 2D spectral/\emph{hp} elements with 1D Fourier expansions are used to discretise the cross stream plane and streamwise flow respectively. The use of 2D spectral/\emph{hp} elements in the cross stream plane is necessary to represent the riblet geometry (\cite{chu_1993}). The time- and spatially-varying velocity and pressure in the cross stream planes are approximated as a finite sum of 2D modified Jacobi polynomials up to the $P^{th}$-order,
\renewcommand{\arraystretch}{1.} % Default value: 1
\begin{equation}\label{eq:crossStream}
    \begin{bmatrix}
        \mathbf{u}^\delta(y,z,t) \\
        p^\delta(y,z,t)
    \end{bmatrix}
    =
    \sum_{p=0}^P \sum_{q=0}^P \psi_p(y) \psi_q(z)
    \begin{bmatrix}
         \hat{\mathbf{u}}_{p,q}(t) \\
         \hat{p}_{p,q}(t)
    \end{bmatrix}
\end{equation}
where $\hat{\mathbf{u}}_{p,q}(t)$ and $\hat{p}_{p,q}(t)$ are the time-varying coefficients. Extending equation \ref{eq:crossStream} to include the streamwise direction represented by Fourier expansions,
\begin{equation}\label{eq:fourierSpectral}
    \begin{bmatrix}
        \mathbf{u}^\delta(x,y,z,t) \\
        p^\delta(x,y,z,t)
    \end{bmatrix}
    =
    \sum_{k=0}^{N-1} \sum_{p=0}^P \sum_{q=0}^P \psi_p(y) \psi_q(z) e^{ik\alpha x}
    \begin{bmatrix}
         \hat{\mathbf{u}}_{p,q,k}(t) \\
         \hat{p}_{p,q,k}(t)
    \end{bmatrix}
    =
    \sum_{k=0}^{N-1} e^{ik\alpha x} \begin{bmatrix}
        \mathbf{u}_k(y,z,t) \\ p_k(y,z,t)
    \end{bmatrix}
\end{equation}
where $\alpha = \frac{2\pi}{L_x}$ is the streamwise wavenumber, $L_x$ is the streamwise domain length and $N$ refers to the number of Fourier expansions. Substituting equation \ref{eq:fourierSpectral} into the Navier-Stokes equations and taking the Fourier transform (equivalently to the Galerkin projection with respect to Fourier expansion as a test function) yields $N$-systems of equations,
\begin{equation}
    \frac{\partial \mathbf{u}_k}{\partial t} = - \tilde{\nabla}_k p_k + \nu(\nabla^2_{y,z} - k^2\alpha^2)\mathbf{u}_k - \widehat{\left[(\mathbf{u} \cdot \nabla) \mathbf{u}\right]}_k, \qquad \tilde{\nabla}\mathbf{u}_k = 0
\end{equation}
where, $\tilde{\nabla} = (ik\alpha, \frac{\partial}{\partial y}, \frac{\partial}{\partial z})$, $\nabla_{y,z}^2 = (\frac{\partial^2}{\partial y^2}, \frac{\partial^2}{\partial z^2})$ and $\widehat{\left[(\mathbf{u} \cdot \nabla) \mathbf{u} \right]_k}$ refers to the Fourier-transformed of the $k^{th}$ nonlinear term.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 3.3 TEMPORAL DISCRETISATIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Temporal Discretisation}\label{sec:temporalDiscret}
The velocity and pressure fields obtained from the Navier-Stokes equations are time dependent. A separate class of numerical methods used for temporal discretisation will be covered in this section. Temporal discretisation methods, used to solve initial value problems (IVPs) can be broadly categorised into two schemes:

\begin{enumerate}
    \item Multi-stage schemes that advance the solution from the $n^{th}$ to $n^{th}+1$ time-step through a number of intermediate stages which are not solutions at the previous time-steps. The class of Runge-Kutta schemes is an example of multi-staged schemes. In general, multi-stage schemes are typically computationally intensive as extra intermediate steps are required to be computed.
    \item Multi-step schemes that advance the solution from the $n^{th}$ to $n^{th}+1$ time-step using information from the from the previous $n^{th}-1$ time-step. The Adams-Bashforth and Adams-Moulton methods are examples of multi-step schemes. Multi-step schemes are typically more memory intensive as the solution from the previous time-steps are stored.
\end{enumerate}

\cite{butcher_2006} proposed the General Linear Method that formalise any multi-stage, multi-step stepping scheme. The general linear method is also flexible to accommodate various implicit, explicit methods. Implicit methods are methods in which the solution at the $n^{th} + 1$ time-step depends on some parameters at the $n^{th}+1$ time-step. Explicit methods are methods in which the solution at time-step $n^{th}+1$ depends only on parameters from the previous time-steps. In this section, the basic ideas of the generalised linear method will be introduced, followed by the implicity-explicit (IMEX) schemes, which are temporal discretisation schemes used in \emph{nektar++}.

% \subsection{Generalised Linear Method}
Consider an initial value problem of the following,
\begin{equation}
    \frac{d\mathbf{u}}{dt} = \mathbf{f}(\mathbf{u}), \quad \mathbf{u}(t_0) = \mathbf{u}_0,
\end{equation}
where $\mathbf{u}_0$ is the initial condition. The $n^{th}+1$ step of the genereal linear method consist of $r$ steps and $s$ stages,
\begin{equation}\label{eq:stage}
    \mathbf{Y}_i = \Delta t \sum_{j=1}^sa_{ij}\mathbf{F}_j + \sum_{j=1}^ru_{ij}\mathbf{u}_j^n, \qquad 1 < i < s,
\end{equation}
\begin{equation}\label{eq:steps}
    \mathbf{u}_i^{n+1} = \Delta t \sum_{j=1}^sb_{ij}\mathbf{F}_j + \sum_{j=1}^rv_{ij}\mathbf{u}_j^n, \qquad 1 < i < r,
\end{equation}
where, $\mathbf{Y}_i, \, \mathbf{F}_i$ is known as to the stage values and derivatives respectively related by,
\begin{equation}
    \mathbf{F}_i = \mathbf{f}(\mathbf{Y}_i).
\end{equation}
The coefficient matrix $A=a_{ij},\, B=b_{ij},\, U=u_{ij},\, V=v_{ij}$ uniquely defines the time integration scheme and equation \ref{eq:stage} and \ref{eq:steps} can be re-written as,
\renewcommand{\arraystretch}{1.0} % Default value: 1
\begin{equation}\label{eq:glmMatrix}
    \begin{bmatrix}
        \mathbf{Y} \\ 
        \mathbf{u}^{n+1}
    \end{bmatrix}
    =
    \begin{bmatrix}
        A \otimes I & U \otimes I \\
        B \otimes I & V \otimes I
    \end{bmatrix}
    \begin{bmatrix}
        \Delta t \mathbf{F} \\
        \mathbf{u}^{n}
    \end{bmatrix},
\end{equation}
\begin{equation}
    \mathbf{Y} = 
    \begin{bmatrix}
        \mathbf{Y}_1 \\ \vdots \\ \mathbf{Y}_s
    \end{bmatrix},
    \quad
    \mathbf{F} = 
    \begin{bmatrix}
        \mathbf{F}_1 \\ \vdots \\ \mathbf{F}_s
    \end{bmatrix},
    \quad
    \mathbf{u}^{n+1} = 
    \begin{bmatrix}
        \mathbf{u}^{n+1}_1 \\ \vdots \\ \mathbf{u}^{n+1}_r
    \end{bmatrix},
    \quad
    \mathbf{u^n} = 
    \begin{bmatrix}
        \mathbf{u}^n_1 \\ \vdots \\ \mathbf{u}^n_r
    \end{bmatrix}.
\end{equation}
It is worth noting that $\mathbf{u}_1^{n+1}$, the first element in $\mathbf{u}^{n+1}$ is the solution at the $n^{th}+1$ time-step. The other elements in $\mathbf{u}^n$ refer to the intermediate steps of a multi-step scheme.
% \subsection{Implicit-Explicit Scheme}
The implicit-explicit (IMEX) scheme is a type of time-integration scheme used in \emph{nektar++}, where different terms in the Navier-Stokes equation are treated either explicitly, or implicitly. Using the generalised linear method, the IMEX method will be illustrated in this section. IMEX schemes are used to integrate an ordinary differential equation (ODE) of the following,
\begin{equation}
    \frac{\mathrm{d}\mathbf{u}}{\mathrm{d}t} = \mathbf{f}(\mathbf{u}) + \mathbf{g}(\mathbf{u}), \quad \mathbf{u}(t_0) = \mathbf{u}_0,
\end{equation}
where $\mathbf{f}(\mathbf{u})$ is the stiff function and integrated implicitly while $\mathbf{g}(\mathbf{u})$ is a non-linear function and integrated explicitly. The IMEX general linear method is rewritten in the form of,
\begin{equation}
    \mathbf{Y}_i = \Delta t \sum_{j=1}^s a_{ij}^{\textrm{IM}}\mathbf{F}_j + \Delta t \sum_{j=1}^s a_{ij}^{\textrm{EX}} \mathbf{G}_j + \sum_{j=1}^r u_{ij}\mathbf{u}_j^n, \qquad 1 \leq i \leq s,
\end{equation}
\begin{equation}
    \mathbf{u}_i^n = \Delta t \sum_{j=1}^s b_{ij}^{\textrm{IM}}\mathbf{F}_j + \Delta t \sum_{j=1}^s b_{ij}^{\textrm{EX}} \mathbf{G}_j + \sum_{j=1}^r v_{ij}\mathbf{u}_j^n, \qquad 1 \leq i \leq r,
\end{equation}
where $\mathbf{F}_i$ and $\mathbf{G}_i$ are the stage derivatives given as,
\begin{equation}
    \mathbf{F}_i = \mathbf{f}(\mathbf{Y}_i), \qquad \mathbf{G}_i = \mathbf{g}(\mathbf{Y}_i).
\end{equation}
Similar to equation \ref{eq:glmMatrix}, the above equations can be re-written in matrix form,
\begin{equation}\label{eq:glmMatrixIMEX}
    \begin{bmatrix}
        \mathbf{Y} \\ 
        \mathbf{u}^{n+1}
    \end{bmatrix}
    =
    \begin{bmatrix}
        A^\textrm{IM} \otimes I & A^\textrm{EX} \otimes I & U \otimes I \\
        B^\textrm{IM} \otimes I & B^\textrm{EX} \otimes I & V \otimes I
    \end{bmatrix}
    \begin{bmatrix}
        \Delta t \mathbf{F} \\
        \Delta t \mathbf{G} \\
        \mathbf{u}^{n}
    \end{bmatrix},
\end{equation}
The family of stiffly stable schemes (\cite{karniadakis_1991}) which are IMEX in nature, are used in to time-integrate the incompressible Navier-Stokes equations in \emph{nektar++}. The partitioned matrix for the second-order stiffly stable schemes is given as,
\begin{equation}
    \begin{bmatrix}
        A^\textrm{IM} \otimes I & A^\textrm{EX} \otimes I & U \otimes I \\
        B^\textrm{IM} \otimes I & B^\textrm{EX} \otimes I & V \otimes I
    \end{bmatrix}
    =
    \begin{bmatrix}
        \frac{2}{3} & 0 & \frac{4}{3} & -\frac{1}{3} & \frac{4}{3} & -\frac{2}{3} \\
        \frac{2}{3} & 0 & \frac{4}{3} & -\frac{1}{3} & \frac{4}{3} & -\frac{2}{3} \\
        1 & 0 & 0 & 0 & 0 & 0 \\
        0 & 1 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & 1 & 0
    \end{bmatrix},
    \quad \textrm{with} \quad
    \mathbf{u}^{n+1}
    =
    \begin{bmatrix}
        \mathbf{u}^{n+1} \\
        \mathbf{u}^{n} \\
        \Delta t \mathbf{F}^{n+1} \\
        \Delta t \mathbf{F}^{n}
    \end{bmatrix}.
\end{equation}
% \subsection{Spatial discretisation}
% \subsubsection{1D Spectral-\emph{h/p} elements}
% \subsubsection{2D Spectral-\emph{h/p} elements}
% \subsubsection{Quasi-3D Fourier-spectral-\emph{hp} elements}
% \subsection{Temporal discretisation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 3.4 VELOCITY CORRECTION SCHEME
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Velocity correction scheme for incompressible Navier Stokes equations}
While methods for temporal and spatial discretisation have been discussed, it is not possible to apply these techniques in a straight-forward manner to the incompressible Navier-Stokes equations. This is because of the unique role of the pressure field which ensures that the time-dependent velocity field is divergence-free. However, the velocity and the pressure fields form a coupled-system through the continuity and momentum equations which requires the solution of both fields simultaneously. In general, there are 3 ways to deal with velocity-pressure coupling: (1) Coupled methods (\emph{Uzawa} method), (2) Change of variables (streamfunction-vorticity formulation) and (3) Splitting methods which decouples velocity and pressure. The velocity correction scheme (VCS) (\cite{karniadakis_1991}), a type of splitting method, decouples the velocity field from the pressure field used in \emph{nektar++} will be discussed in this section. The velocity correction scheme is a stiffly-stable time-integration (IMEX) scheme which treats the nonlinear terms (advection) explicitly and linear terms (pressure gradient and diffusion) implicitly.
The VCS will be demonstrated through a worked example. The incompressible Navier-Stokes equations with unit density, constant density and viscosity is written as,
\begin{equation}\label{eq:navierStokes}
    \frac{\partial \mathbf{u}}{\partial t} = \mathrm{\mathbf{N}(\mathbf{u})} - \nabla p +  \nu \mathrm{\mathbf{L}}(\mathbf{u}), \qquad \nabla \cdot \mathbf{u},
\end{equation}
where $\mathbf{u},\; p,\; \rho,\; \nu$ refers to the fluid's velocity, pressure, density and kinematic viscosity respectively. The convection and diffusion terms are conveniently written as nonlinear and linear functions,
\begin{equation}
    \mathrm{\mathbf{N}}(\mathbf{u}) \equiv - (\mathbf{u} \cdot \nabla)\mathbf{u} = -\frac{1}{2}\left[(\mathbf{u} \cdot \nabla )\mathbf{u} + \nabla\cdot(\mathbf{u}\mathbf{u})\right], \qquad \mathrm{\mathbf{L}}(\mathbf{u}) \equiv \nabla^2 \mathbf{u}.
\end{equation}
The nonlinear terms are written in the skew-symmetric to minimise aliasing errors (\cite{karniadakis_1991}). The first step in the scheme is to time integrate the nonlinear terms explicitly,
\begin{equation}\label{eq:firstStep}
    \frac{\mathbf{\hat{u}} - \sum_{q=0}^{J_e-1} \alpha_{q} \mathbf{u}^{n-q}}{\Delta t} = \sum_{q=0}^{J_e-1} \beta_q \mathrm{\mathbf{N}}(\mathbf{u}^{n-q}),
\end{equation}
where $\mathbf{\hat{u}}$ is the first intermediate velocity field, $J_e$ denotes the order of the explicit scheme, superscript $n$ denotes the solution at the $n^{th}$ time-step and $\alpha_q,\; \beta_q$ refers to constant related to the IMEX schemes. Next, the second intermediate velocity field $\hat{\hat{\mathbf{u}}}$ is obtained from the gradient of the pressure field at $n+1$,
\begin{equation}\label{eq:secondStep}
    \frac{\mathbf{\hat{\hat{u}}} - \mathbf{\hat{u}}}{\Delta t} = -\nabla p^{n+1}.
\end{equation}
However, the pressure field at time-step $n+1$ is not known. Taking the divergence of equation \ref{eq:secondStep}, and assuming that $\hat{\hat{\mathbf{u}}}$ is divergence-free, the Poisson equation for pressure is given as,
\begin{equation}\label{eq:pressurePoisson}
    \nabla^2 p^{n+1} = \nabla \cdot \left(\frac{\mathbf{\hat{u}}}{\Delta t}\right).
\end{equation}
with the following boundary condition,
\begin{equation}\label{eq:pressureBC}
\frac{\partial p^{n+1}}{\partial n} = \mathbf{n} \cdot \left(\frac{\mathbf{\hat{\hat{u}}} - \mathbf{\hat{u}}}{\Delta t}\right)
\end{equation}
However, this boundary condition often suffer from splitting errors and may lead to wrong solutions (\cite{karniadakis_1991}). To rectify this, the boundary condition is directly obtain by taking normal dot product with \ref{eq:navierStokes} and evaluated explicity (\cite{alessandro_phd_2013}),
\begin{equation}\label{eq:modifiedpressureBC}
    \frac{\partial p^{n+1}}{\partial t} = -\sum_{q=0}^{J_e-1} \beta_q \left[ \frac{1}{\Delta t} \mathbf{u}^{n-q} + \nu (\nabla \times \omega^{n-q}) + (\mathbf{u}^{n-q} \cdot \nabla)\mathbf{u}^{n-q} \right] \cdot \mathbf{n}.
\end{equation}
where $\omega = \nabla \times \mathbf{u}$, $J_e$ is the order for the explicit scheme, $\beta_q$ is the coefficient related to the time-integration scheme. We obtain the pressure field at time-step $n+1$ by solving the pressure Poisson equation (\ref{eq:pressurePoisson}) with the modified boundary conditions (\ref{eq:modifiedpressureBC}). Then, the second intermediate velocity field $\hat{\hat{\mathbf{u}}}$ is obtained from equation \ref{eq:secondStep}. Finally, the velocity field at $n+1$ is obtain from the final step of the scheme by solving
\begin{equation}\label{eq:thirdStep}
    \frac{\gamma_0\mathbf{u}^{n+1} - \hat{\hat{\mathbf{u}}}}{\Delta t} = \nu \sum_{q=0}^{J_i-1} \beta_q \mathrm{\mathbf{L}}(\mathbf{u}^{n+1-q}), \qquad \mathbf{u}^{n+1}|_{\delta\Omega} = g_D
\end{equation}
where $J_i$ denotes the order of the implicit scheme, $\gamma_0,\; \beta_q$ are coefficients related to the stiffly stable time-integration scheme and $\mathbf{u}^{n+1}$ satisfies the Dirichlet boundary conditions. Table \ref{tab:stiffyStableCoefficients} shows the coefficients of stiffly-stable time-integration schemes (\cite{alessandro_phd_2013}).
\renewcommand{\arraystretch}{1.5} % Default value: 1
\begin{table}[h]
    \centering
        \begin{tabular}{c|c|c}
            test & $1^{st}$ order & $2^{nd}$ order \\
            \hline
            $\gamma_0$ & 1 & 3/2 \\
            $\beta_0$ & 1 & 2 \\
            $\beta_1$ & 0 & -1 \\
            $\alpha_0$ & 0 & -1/2 \\
            $\alpha_1$ & 0 & 0 
        \end{tabular}
        \caption{Stiffly-stable splitting scheme coefficients}
    \label{tab:stiffyStableCoefficients}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 3.5 LINEAR STABILITY ANALYSIS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Linear Stability Analysis}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 3.6 EDGE-TRACKING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Edge Tracking}
% \section{Hydrodynamic stability analysis}
% \subsection{Linear stability analysis}
% \subsubsection{Fourier-Chebyshev methods}
% \subsubsection{Timestepping methods: Arnoldi Iteration}
% \subsubsection{Transient growth}
To study the dynamics of infinitetisimal perturbations about a base flow, the time evolution equation for the perturbations dynamics typically reduces to,
\begin{equation}
    \frac{\partial}{\partial t} \mathbf{u} = \mathcal{L}\mathbf{u},
\end{equation}
where $\mathcal{L}, \mathbf{u}$ refers to the linearised operator and a vector of perturbations. Suppose the that linear operator is diagonlisable,
\begin{equation}
    \mathcal{L} = 
     \begin{bmatrix}
     | & & | \\
     \mathbf{s}_1 & \cdots & \mathbf{s}_n \\
     | & & |
     \end{bmatrix}
     \begin{bmatrix}
     \lambda_1 &  & 0 \\
      & \ddots &  \\
     0 &  & \lambda_n
     \end{bmatrix}
     \begin{bmatrix}
     | & & | \\
     \mathbf{s}_1 & \cdots & \mathbf{s}_n \\
     | & & |
     \end{bmatrix}^{-1}
     = \mathcal{S}\Lambda\mathcal{S}^{-1}.
\end{equation}

Suppose we can decompose our initial conditions into a superposition of eigenmodes,
\begin{equation}
    \mathbf{u}_0 = \alpha_{1,0}\mathbf{s}_1 + \alpha_{2,0}\mathbf{s}_2 + ... + \alpha_{N,0} \mathbf{s}_n = \sum_{i=1}^{n} \alpha_{i,0}\mathbf{s}_i,
\end{equation}
and w

% \subsection{Nonlinear stability tools}
\subsubsection{Edge state tracking}
\subsubsection{Computing Invariant solutions}
